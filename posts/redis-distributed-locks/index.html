<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Redis 用例：分布式锁｜六开箱</title><meta name=keywords content="Redis,分布式锁,使用,教程"><meta name=description content="使用 Redis 来实现分布式锁。"><meta name=author content="六开箱"><link rel=canonical href=https://lkxed.github.io/posts/redis-distributed-locks/><link crossorigin=anonymous href=/assets/css/stylesheet.min.09b98575a0a9c52a0dcff6660328188f9365049be8c47253f3072a85d10d82a5.css integrity="sha256-CbmFdaCpxSoNz/ZmAygYj5NlBJvoxHJT8wcqhdENgqU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://lkxed.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lkxed.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lkxed.github.io/favicon-32x32.png><link rel=manifest href=https://lkxed.github.io/site.webmanifest><link rel=apple-touch-icon href=https://lkxed.github.io/apple-touch-icon.png><link rel=mask-icon href=https://lkxed.github.io/safari-pinned-tab.svg><meta name=theme-color content="#f5f5f5" media="(prefers-color-scheme: light)"><meta name=theme-color content="#1d1e20" media="(prefers-color-scheme: dark)"><meta name=msapplication-TileColor content="#ffffff"><noscript><style>.top-link{display:none}</style></noscript><meta name=shenma-site-verification content="0834e815906a93375245a759f409f8b0_1648880760"><meta name=baidu-site-verification content="code-2I1Hg4GETM"><meta name=google-site-verification content="xBkkt93v_nso_R-2aQ-An4rbc_Gi_4rNFi8oBEKDNjc"><meta property="og:title" content="Redis 用例：分布式锁"><meta property="og:description" content="使用 Redis 来实现分布式锁。"><meta property="og:type" content="article"><meta property="og:url" content="https://lkxed.github.io/posts/redis-distributed-locks/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-04-30T14:55:40+08:00"><meta property="article:modified_time" content="2022-04-30T14:55:40+08:00"><meta property="og:see_also" content="https://lkxed.github.io/posts/redis-bulk-loading/"><meta property="og:see_also" content="https://lkxed.github.io/posts/redis-persistence-backup-recovery/"><meta property="og:see_also" content="https://lkxed.github.io/posts/redis-persistence-usage/"><meta property="og:see_also" content="https://lkxed.github.io/posts/redis-persistence-pros-cons/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Redis 用例：分布式锁"><meta name=twitter:description content="使用 Redis 来实现分布式锁。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"文章","item":"https://lkxed.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Redis 用例：分布式锁","item":"https://lkxed.github.io/posts/redis-distributed-locks/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Redis 用例：分布式锁","name":"Redis 用例：分布式锁","description":"使用 Redis 来实现分布式锁。","keywords":["Redis","分布式锁","使用","教程"],"articleBody":" 使用 Redis 来实现分布式锁。\n 前言 若某个场景涉及到了多个进程互斥地操作共享数据，那么分布式锁会是一种很有用的机制。\n目前，网络上已经有很多使用 Redis 实现分布式锁管理器（DLM）的教程，甚至是第三方库。但是，每个库的实现方式都不同，一些库使用的方式过于简单，和稍微复杂一点的设计相比，它们能够提供的保证更少。\n本文介绍了一种更加规范的算法，用于使用 Redis 实现分布式锁。这个算法叫做 RedLock，它实现了一个分布式锁管理器（DLM），比普通的单例方式要安全得多。\nRedlock 实现 在开始介绍之前，你可以看看下面这些链接，它们是各个语言对该算法的实现，供你参考：\n Redlock-rb —— Ruby 实现 Redlock-py —— Python 实现 Pottery —— Python 实现 Aioredlock —— Python 的异步实现 Redlock-php —— PHP 实现 PHPRedisMutex —— PHP 的进一步实现 cheprasov/php-redis-lock —— PHP 实现。 rtckit/react-redlock —— PHP 的异步实现。 Redsync —— Go 实现。 Redisson —— Java 实现。 Redis::DistLock —— Perl 实现。 Redlock-cpp —— C++ 实现。 Redlock-cs —— C# .NET 实现。 RedLock.net —— C# .NET 实现，包括异步和锁扩展支持。 ScarletLock —— C# .NET 实现，包括可配置的数据存储。 Redlock4Net —— C# .NET 实现。 node-redlock —— NodeJS 实现，包括锁扩展支持。  锁的安全和存活保证 下面我将介绍三个属性，它们是实现一个高效的分布式锁的最低要求。这三个属性分别为：\n 互斥性：在任何时刻，只有一个客户端可以持有锁。 存活性：不会产生死锁，也就是说，客户端最终总是能够获取到锁，即使持有锁的客户端崩溃或者被分区。 容错性：只要多数的 Redis 节点存活，客户端就能够正常地获取或释放锁。  基于故障转移的实现 为了理解 Redlock 算法有什么改进，让我们先来分析一下目前大多数基于 Redis 实现的分布式锁，对其中涉及到的环节进行评估。\n使用 Redis 来实现分布式锁的最简单的方式，就是在单个实例中创建一个 key。这个 key 通常在创建时就设置了有限的存活时间（通过 Redis 的 key 过期特性），这样一来，无论如何，它最终都会被释放（即实现了上面的存活性）。当客户端需要释放资源时，它只要把 key 删除掉即可。\n这个算法看起来很好，但实际上，它有一个致命的问题：这么做会给当前架构引入一个单点故障。\n万一 Redis 主节点宕机了怎么办呢？嗯……那就加个副本吧！当主节点不可用时，转而使用它的副本。\n然而，不幸的是，这也是不可行的。如果这样做，我们就不能够实现互斥性，因为 Redis 是异步复制的。\n下面是这个模型的竞态条件：\n 客户端 A 在主节点上获取到了锁（创建了 key）。 主节点宕机，创建 key 的操作还没来得及发送到副本上。 副本被提升为主节点。 客户端 B 获取到了 A 正在持有的同一个锁。互斥性被破坏！  有时候，在特殊场景下，例如在故障时，许多客户端可能持有同一个锁，这是完全可以接受的。如果是这种情况，那么你可以使用基于复制的解决方案。否则，建议你实现本文介绍的 Redlock 算法来生成和管理分布式锁。\n单实例算法的正确实现方式 在尝试克服单实例的局限性（单点故障）之前，让我们先来看看如何正确地实现上述的简单算法。一方面，因为对于某些应用程序来说，它们有时可以接受竞态条件，这不失为一个可行方案。另一方面，也因为单实例锁是本文介绍的分布式锁算法的基础。\n若要获得锁，执行下面的命令：\nSET resource_name my_random_value NX PX 3000 在这个命令中，key 只会在其不存在时才被创建并设值（通过 NX 选项），并且会在 30000 毫秒后过期（通过 PX 选项）。上述 key 的值被设置为“my_random_key”。在实践中，这个值必须在所有客户端和锁申请中唯一。\n基本上，这个随机值的用途就是安全地释放锁，同时还要结合脚本来告诉 Redis：只在 key 存在、且其值和预期相同时，才删除该 key（释放锁）。这是通过下面的 Lua 脚本实现的：\nif redis.call(\"get\", KEYS[1]) == ARGV[1] then return redis.call(\"del\", KEYS[1]) else return 0 end 这么做很重要，目的是避免移除别的客户端创建的 key。\n举个例子，当一个客户端获得锁后，开始执行一些耗时操作，还没有执行完，锁就失效了（key 过期了）。之后，由于 key 清理策略的存在，过期的锁（key）被清理，然而在此之前，别的客户端已经获得了该锁。这将导致互斥性被破坏。\n单纯使用 DEL 是不安全的，因为一个客户端能够释放另一个客户端已经持有的锁。使用上述脚本后，每个锁都与随机字符串唯一绑定，这样一来，只有获得锁的客户端才能够释放锁。\n那么，这个随机字符串应该是什么呢？它默认为 /dev/urandom 的前 20 个字节。不过，对于具体的应用场景，你或许能够找到代价更小的方案来生成一个足够唯一unique的值。\n例如，若要保证绝对安全，你可以使用 /dev/urandom 来作为 RC4 的种子，然后从中生成一个伪随机流。\n不过，你也可以选择使用更简单的方式：直接结合 UNIX 时间戳和客户端 ID。它没有前者安全，但是对于大多数场景来说，它都足够安全了。\n“锁的有效时间”就是我们设置的 key 过期时间。它同时也是锁的自动释放时间，是客户端在获得锁后可以执行操作的时间，时间到后，别的客户端就能够获取到锁，而不会破坏锁的互斥性。不过，锁的互斥保证仅限于锁被获得后的一段时间内。\n现在，我们有了一个获得/释放锁的好方法。有了这个机制，由单个永久可用的实例组成的非分布式的系统，也是安全的。\n那么，如何把这个机制扩展到更复杂的分布式系统呢？\nRedlock 算法 在以上算法的分布式版本中，我们假设有 N 个 Redis 主节点。这些节点互相独立，所以我们不需要复制或任何其他隐式协调机制。\n由于已经介绍了在单实例上安全地获得/释放锁的算法，我们默认在 N = 1 时使用它。\n在下面的例子中，我们设 N = 5，这是一个合理的值。这意味着我们需要 5 个主节点，并让它们分别运行在不同的主机或者虚拟机上，以此来保证它们故障时互不影响。\n算法流程 在这个算法中，客户端获得锁的流程为：\n 获取当前时间（毫秒）。 顺序地尝试在 N 个主机上获得锁，在这个过程中使用同一个 key 和随机值。当设置 key 值时，客户端使用了一个相对短的超时时间（与锁的有效时间相比）。若超过这个时间还未能成功设置 key 值，那就放弃操作。例如，若锁的有效时间为 10 秒，这个超时时间可能只有 5 到 50 毫秒。这么做能够防止客户端长时间尝试和一个已经宕机的节点通信：如果一个实例不可用，我们应该立即转而尝试下一个。 客户端计算获得锁所需的时间，计算方式为把当前的时间减去步骤 1 中获取的时间戳。当且仅当客户端能够在多数节点中获得锁，并且获得锁所需的时间小于锁的有效时间，它才会被认为成功获得了锁。 如果客户端获得了锁，锁的有效时间将会是它的初始值减去步骤 3 中计算出来的所需时间。 如果客户端由于某些原因未能获得锁（要么是它不能够至少锁住 N/2 个实例，要么是有效时间为负值），它都会尝试释放所有实例的锁（包括那些它未能成功获得锁的实例）。  异步 这个算法的正确性依赖于一个假设：进程之间没有同步锁，且每个进程的本地时间都以大致相同的速率更新，就算有误差，和锁的自动释放时间相比，它也应该很小才行。\n这个假设与现实世界中的计算机非常相似：每台计算机都有本地时钟，我们通常可以依赖于许多不同的计算机，来获得一个小的时钟漂移。\n到了这个时候，我们需要更好地定义互斥规则：只有在特定条件被满足时，互斥性才能够被保证。这个条件是，在步骤 3 中获得锁的客户端要某个时间前结束工作，这个时间就是锁的有效时间减去一小段时间（大概几毫秒，用于补充进程间的时钟漂移）。\n你可以阅读 《Leases：一个高效、可容错的分布式文件缓存一致性机制》 ，它是发表在 ACM 上的一篇论文，其中包含了更多关于绑定时钟漂移的介绍。\n失败重试 当某个客户端不能获得锁时，它应该在随机延迟后重试，以便尝试取消多个试图同时获取同一资源锁的客户端的同步（这可能会导致无人获胜的脑裂情况）。此外，在大多数 Redis 实例中，客户端尝试获取锁的速度越快，脑裂情况的时间窗口就越小（并且需要重试）。因此，在理想情况下，客户端应该尝试使用多路复用技术，同时向 N 个实例发送 SET 命令。\n值得强调的是，对于未能获得多数锁的客户来说，尽快释放（部分）获得的锁是十分重要的。这样一来，它就不需要等待 key 过期才能再次获取锁（但是，如果发生网络分区，客户端就不再能够与 Redis 实例通信，那么在等待 key 过期时，系统的可用性会降低）。\n锁释放 释放锁是很简单的，无论客户端认为自己能够成功锁定给定的实例，它都可以执行释放锁。\n安全保证 这个算法是安全的吗？我们可以设想以下场景来验证。\n作为开始，让我们假设客户端能够获得多数实例的锁。所有的实例上都有一个相同的 key，并且它们的存活时间也相同。然而，这个 key 是在不同时间被设置的，因此它们的过期时间是不同的。但是，我们可以假设一种最坏的情况，即：第一个 key 设置于 T1 时刻（假设此时还未与第一个服务端通信），而最后一个 key 设置于 T2（假设此时获得到了最后一个服务端的响应），那么我们可以确定第一个 key 至少会存活 MIN_VALIDITY = TTL - (T2 - T1) - CLOCK_DRIFT 那么长的时间。所有其他的 key 都会在这之后过期，那么我们就可以确定这些 key 会被同时设置至少一次。\n在这段时间里，多数 key 都被设置，另一个客户端将不能够获得锁，因为 SET NX 不可能成功 N/2 + 1 次，如果已经存在了 N/2 + 1 个 key 的话。因此，如果一个锁已被获得，它就不可能同时又被重新获得（破坏互斥性）。\n不过，我们还需要确保多个客户端同时尝试获得锁时，它们不会同时成功。\n如果客户端在一个接近于或是大于锁最大有效时间（就是使用 SET 命令时的 TTL）之内，锁住了多数实例，它就会认为这个锁是无效的，继而解锁所有实例。所以，我们只需要考虑一种情况：当客户端能够在锁有效时间内，成功锁住多数实例。在这个情况下，由于前面已经提到的原因，客户端将无法重新获得锁。因此，当多个客户端能够同时锁定 N/2 + 1 个实例（在步骤 2 中描述的时间内），当且仅当锁住多数实例的耗时要大于 TTL，而这样在这种情况下锁是无效的。\n存活保证 系统存活性依赖于下面三个主要特性：\n 锁自动释放（key 过期）：最终 key 是可以被重新上锁的。 当不能获得锁时，或者当获得了锁，工作结束后，客户端通常都会配合地删除锁。这使得我们很大概率不需要等待 key 过期才能重新获得锁。 当客户端需要重试锁时，它会延迟一段时间，这段时间和获得锁所需时间相比要长，这样一来可以从概率上，避免发生资源争用时的脑裂情况。  然而，由于使用了多台主节点，当网络分区时，我们将会损失 TTL 这么长时间的可用性。如果网络分区持续存在的话，我们的系统将持续不可用。这种情况有可能会发生，如果客户端获得了锁，却在释放锁之前就被分区了的话。\n后语 下一篇文章，我将介绍 Redis 的数据结构。保持关注喔！\n参考  Redis Documentation - Distributed Locks with Redis     本文使用 CC BY-SA 4.0 国际协议 进行许可，欢迎遵照协议规定转载。\n作者：六开箱 链接：https://lkxed.github.io/posts/redis-distributed-locks/  ","wordCount":"4182","inLanguage":"zh","datePublished":"2022-04-30T14:55:40+08:00","dateModified":"2022-04-30T14:55:40+08:00","author":{"@type":"Person","name":"六开箱"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://lkxed.github.io/posts/redis-distributed-locks/"},"publisher":{"@type":"Organization","name":"六开箱","logo":{"@type":"ImageObject","url":"https://lkxed.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://lkxed.github.io/ accesskey=h title="六开箱 (Alt + H)"><img src=https://lkxed.github.io/favicon.ico alt=logo aria-label=logo height=30>六开箱</a></div><ul id=menu><li><a href=https://lkxed.github.io/posts/ title=文章><span>文章</span></a></li><li><a href=https://lkxed.github.io/archives/ title=归档><span>归档</span></a></li><li><a href=https://lkxed.github.io/series/ title=系列><span>系列</span></a></li><li><a href=https://lkxed.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://lkxed.github.io/search/ title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Redis 用例：分布式锁</h1><div class=post-meta><span title="2022-04-30 14:55:40 +0800 CST">2022 年 4 月 30 日</span>&nbsp;·&nbsp;4182 字&nbsp;·&nbsp;六开箱&nbsp;｜&nbsp;<a href=https://github.com/lkxed/ rel="noopener noreferrer" target=_blank>关注我🌟</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#%e5%89%8d%e8%a8%80 aria-label=前言>前言</a></li><li><a href=#redlock-%e5%ae%9e%e7%8e%b0 aria-label="Redlock 实现">Redlock 实现</a></li><li><a href=#%e9%94%81%e7%9a%84%e5%ae%89%e5%85%a8%e5%92%8c%e5%ad%98%e6%b4%bb%e4%bf%9d%e8%af%81 aria-label=锁的安全和存活保证>锁的安全和存活保证</a></li><li><a href=#%e5%9f%ba%e4%ba%8e%e6%95%85%e9%9a%9c%e8%bd%ac%e7%a7%bb%e7%9a%84%e5%ae%9e%e7%8e%b0 aria-label=基于故障转移的实现>基于故障转移的实现</a></li><li><a href=#%e5%8d%95%e5%ae%9e%e4%be%8b%e7%ae%97%e6%b3%95%e7%9a%84%e6%ad%a3%e7%a1%ae%e5%ae%9e%e7%8e%b0%e6%96%b9%e5%bc%8f aria-label=单实例算法的正确实现方式>单实例算法的正确实现方式</a></li><li><a href=#redlock-%e7%ae%97%e6%b3%95 aria-label="Redlock 算法">Redlock 算法</a><ul><li><a href=#%e7%ae%97%e6%b3%95%e6%b5%81%e7%a8%8b aria-label=算法流程>算法流程</a></li><li><a href=#%e5%bc%82%e6%ad%a5 aria-label=异步>异步</a></li><li><a href=#%e5%a4%b1%e8%b4%a5%e9%87%8d%e8%af%95 aria-label=失败重试>失败重试</a></li><li><a href=#%e9%94%81%e9%87%8a%e6%94%be aria-label=锁释放>锁释放</a></li><li><a href=#%e5%ae%89%e5%85%a8%e4%bf%9d%e8%af%81 aria-label=安全保证>安全保证</a></li><li><a href=#%e5%ad%98%e6%b4%bb%e4%bf%9d%e8%af%81 aria-label=存活保证>存活保证</a></li></ul></li><li><a href=#%e5%90%8e%e8%af%ad aria-label=后语>后语</a></li><li><a href=#%e5%8f%82%e8%80%83 aria-label=参考>参考</a></li></ul></div></details></div><div class=post-content><blockquote><p>使用 Redis 来实现分布式锁。</p></blockquote><h2 id=前言>前言<a hidden class=anchor aria-hidden=true href=#前言>#</a></h2><p>若某个场景涉及到了多个进程互斥地操作共享数据，那么分布式锁会是一种很有用的机制。</p><p>目前，网络上已经有很多使用 Redis 实现分布式锁管理器（DLM）的教程，甚至是第三方库。但是，每个库的实现方式都不同，一些库使用的方式过于简单，和稍微复杂一点的设计相比，它们能够提供的保证更少。</p><p>本文介绍了一种更加规范的算法，用于使用 Redis 实现分布式锁。这个算法叫做 <strong>RedLock</strong>，它实现了一个分布式锁管理器（DLM），比普通的单例方式要安全得多。</p><h2 id=redlock-实现>Redlock 实现<a hidden class=anchor aria-hidden=true href=#redlock-实现>#</a></h2><p>在开始介绍之前，你可以看看下面这些链接，它们是各个语言对该算法的实现，供你参考：</p><ul><li><a href=https://github.com/leandromoreira/redlock-rb target=_blank rel="noopener noreferrer">Redlock-rb</a>
—— Ruby 实现</li><li><a href=https://github.com/SPSCommerce/redlock-py target=_blank rel="noopener noreferrer">Redlock-py</a>
—— Python 实现</li><li><a href=https://github.com/brainix/pottery#redlock target=_blank rel="noopener noreferrer">Pottery</a>
—— Python 实现</li><li><a href=https://github.com/joanvila/aioredlock target=_blank rel="noopener noreferrer">Aioredlock</a>
—— Python 的异步实现</li><li><a href=https://github.com/ronnylt/redlock-php target=_blank rel="noopener noreferrer">Redlock-php</a>
—— PHP 实现</li><li><a href=https://github.com/malkusch/lock#phpredismutex target=_blank rel="noopener noreferrer">PHPRedisMutex</a>
—— PHP 的进一步实现</li><li><a href=https://github.com/cheprasov/php-redis-lock target=_blank rel="noopener noreferrer">cheprasov/php-redis-lock</a>
—— PHP 实现。</li><li><a href=https://github.com/rtckit/reactphp-redlock target=_blank rel="noopener noreferrer">rtckit/react-redlock</a>
—— PHP 的异步实现。</li><li><a href=https://github.com/go-redsync/redsync target=_blank rel="noopener noreferrer">Redsync</a>
—— Go 实现。</li><li><a href=https://github.com/mrniko/redisson target=_blank rel="noopener noreferrer">Redisson</a>
—— Java 实现。</li><li><a href=https://github.com/sbertrang/redis-distlock target=_blank rel="noopener noreferrer">Redis::DistLock</a>
—— Perl 实现。</li><li><a href=https://github.com/jacket-code/redlock-cpp target=_blank rel="noopener noreferrer">Redlock-cpp</a>
—— C++ 实现。</li><li><a href=https://github.com/kidfashion/redlock-cs target=_blank rel="noopener noreferrer">Redlock-cs</a>
—— C# .NET 实现。</li><li><a href=https://github.com/samcook/RedLock.net target=_blank rel="noopener noreferrer">RedLock.net</a>
—— C# .NET 实现，包括异步和锁扩展支持。</li><li><a href=https://github.com/psibernetic/scarletlock target=_blank rel="noopener noreferrer">ScarletLock</a>
—— C# .NET 实现，包括可配置的数据存储。</li><li><a href=https://github.com/LiZhenNet/Redlock4Net target=_blank rel="noopener noreferrer">Redlock4Net</a>
—— C# .NET 实现。</li><li><a href=https://github.com/mike-marcacci/node-redlock target=_blank rel="noopener noreferrer">node-redlock</a>
—— NodeJS 实现，包括锁扩展支持。</li></ul><h2 id=锁的安全和存活保证>锁的安全和存活保证<a hidden class=anchor aria-hidden=true href=#锁的安全和存活保证>#</a></h2><p>下面我将介绍三个属性，它们是实现一个高效的分布式锁的最低要求。这三个属性分别为：</p><ol><li>互斥性：在任何时刻，只有一个客户端可以持有锁。</li><li>存活性：不会产生死锁，也就是说，客户端最终总是能够获取到锁，即使持有锁的客户端崩溃或者被分区。</li><li>容错性：只要多数的 Redis 节点存活，客户端就能够正常地获取或释放锁。</li></ol><h2 id=基于故障转移的实现>基于故障转移的实现<a hidden class=anchor aria-hidden=true href=#基于故障转移的实现>#</a></h2><p>为了理解 Redlock 算法有什么改进，让我们先来分析一下目前大多数基于 Redis 实现的分布式锁，对其中涉及到的环节进行评估。</p><p>使用 Redis 来实现分布式锁的最简单的方式，就是在单个实例中创建一个 key。这个 key 通常在创建时就设置了有限的存活时间（通过 Redis 的 key 过期特性），这样一来，无论如何，它最终都会被释放（即实现了上面的存活性）。当客户端需要释放资源时，它只要把 key 删除掉即可。</p><p>这个算法看起来很好，但实际上，它有一个致命的问题：这么做会给当前架构引入一个单点故障。</p><p>万一 Redis 主节点宕机了怎么办呢？嗯……那就加个副本吧！当主节点不可用时，转而使用它的副本。</p><p>然而，不幸的是，这也是不可行的。如果这样做，我们就不能够实现互斥性，因为 Redis 是<strong>异步复制</strong>的。</p><p>下面是这个模型的竞态条件：</p><ol><li>客户端 A 在主节点上获取到了锁（创建了 key）。</li><li>主节点宕机，创建 key 的操作还没来得及发送到副本上。</li><li>副本被提升为主节点。</li><li>客户端 B 获取到了 A 正在持有的同一个锁。<strong>互斥性被破坏！</strong></li></ol><p>有时候，在特殊场景下，例如在故障时，许多客户端可能持有同一个锁，这是完全可以接受的。如果是这种情况，那么你可以使用基于复制的解决方案。否则，建议你实现本文介绍的 Redlock 算法来生成和管理分布式锁。</p><h2 id=单实例算法的正确实现方式>单实例算法的正确实现方式<a hidden class=anchor aria-hidden=true href=#单实例算法的正确实现方式>#</a></h2><p>在尝试克服单实例的局限性（单点故障）之前，让我们先来看看如何正确地实现上述的简单算法。一方面，因为对于某些应用程序来说，它们有时可以接受竞态条件，这不失为一个可行方案。另一方面，也因为单实例锁是本文介绍的分布式锁算法的基础。</p><p>若要获得锁，执行下面的命令：</p><pre tabindex=0><code>SET resource_name my_random_value NX PX 3000
</code></pre><p>在这个命令中，key 只会在其不存在时才被创建并设值（通过 <code>NX</code> 选项），并且会在 30000 毫秒后过期（通过 <code>PX</code> 选项）。上述 key 的值被设置为“my_random_key”。在实践中，这个值必须在所有客户端和锁申请中唯一。</p><p>基本上，这个随机值的用途就是安全地释放锁，同时还要结合脚本来告诉 Redis：只在 key 存在、且其值和预期相同时，才删除该 key（释放锁）。这是通过下面的 Lua 脚本实现的：</p><pre tabindex=0><code>if redis.call(&#34;get&#34;, KEYS[1]) == ARGV[1] then
    return redis.call(&#34;del&#34;, KEYS[1])
else
    return 0
end
</code></pre><p>这么做很重要，目的是避免移除别的客户端创建的 key。</p><p>举个例子，当一个客户端获得锁后，开始执行一些耗时操作，还没有执行完，锁就失效了（key 过期了）。之后，由于 key 清理策略的存在，过期的锁（key）被清理，然而在此之前，别的客户端已经获得了该锁。这将导致互斥性被破坏。</p><p>单纯使用 <code>DEL</code> 是不安全的，因为一个客户端能够释放另一个客户端已经持有的锁。使用上述脚本后，每个锁都与随机字符串唯一绑定，这样一来，只有获得锁的客户端才能够释放锁。</p><p>那么，这个随机字符串应该是什么呢？它默认为 <code>/dev/urandom</code> 的前 20 个字节。不过，对于具体的应用场景，你或许能够找到代价更小的方案来生成一个足够<ruby>唯一<rt>unique</rt></ruby>的值。</p><p>例如，若要保证绝对安全，你可以使用 <code>/dev/urandom</code> 来作为 RC4 的种子，然后从中生成一个伪随机流。</p><p>不过，你也可以选择使用更简单的方式：直接结合 UNIX 时间戳和客户端 ID。它没有前者安全，但是对于大多数场景来说，它都足够安全了。</p><p>“锁的有效时间”就是我们设置的 key 过期时间。它同时也是锁的自动释放时间，是客户端在获得锁后可以执行操作的时间，时间到后，别的客户端就能够获取到锁，而不会破坏锁的互斥性。不过，锁的互斥保证仅限于锁被获得后的一段时间内。</p><p>现在，我们有了一个获得/释放锁的好方法。有了这个机制，由单个永久可用的实例组成的非分布式的系统，也是安全的。</p><p>那么，如何把这个机制扩展到更复杂的分布式系统呢？</p><h2 id=redlock-算法>Redlock 算法<a hidden class=anchor aria-hidden=true href=#redlock-算法>#</a></h2><p>在以上算法的分布式版本中，我们假设有 N 个 Redis 主节点。这些节点互相独立，所以我们不需要复制或任何其他隐式协调机制。</p><p>由于已经介绍了在单实例上安全地获得/释放锁的算法，我们默认在 N = 1 时使用它。</p><p>在下面的例子中，我们设 N = 5，这是一个合理的值。这意味着我们需要 5 个主节点，并让它们分别运行在不同的主机或者虚拟机上，以此来保证它们故障时互不影响。</p><h3 id=算法流程>算法流程<a hidden class=anchor aria-hidden=true href=#算法流程>#</a></h3><p>在这个算法中，客户端获得锁的流程为：</p><ol><li>获取当前时间（毫秒）。</li><li>顺序地尝试在 N 个主机上获得锁，在这个过程中使用同一个 key 和随机值。当设置 key 值时，客户端使用了一个相对短的超时时间（与锁的有效时间相比）。若超过这个时间还未能成功设置 key 值，那就放弃操作。例如，若锁的有效时间为 10 秒，这个超时时间可能只有 5 到 50 毫秒。这么做能够防止客户端长时间尝试和一个已经宕机的节点通信：如果一个实例不可用，我们应该立即转而尝试下一个。</li><li>客户端计算获得锁所需的时间，计算方式为把当前的时间减去步骤 1 中获取的时间戳。当且仅当客户端能够在多数节点中获得锁，并且获得锁所需的时间小于锁的有效时间，它才会被认为成功获得了锁。</li><li>如果客户端获得了锁，锁的有效时间将会是它的初始值减去步骤 3 中计算出来的所需时间。</li><li>如果客户端由于某些原因未能获得锁（要么是它不能够至少锁住 N/2 个实例，要么是有效时间为负值），它都会尝试释放所有实例的锁（包括那些它未能成功获得锁的实例）。</li></ol><h3 id=异步>异步<a hidden class=anchor aria-hidden=true href=#异步>#</a></h3><p>这个算法的正确性依赖于一个假设：进程之间没有同步锁，且每个进程的本地时间都以大致相同的速率更新，就算有误差，和锁的自动释放时间相比，它也应该很小才行。</p><p>这个假设与现实世界中的计算机非常相似：每台计算机都有本地时钟，我们通常可以依赖于许多不同的计算机，来获得一个小的时钟漂移。</p><p>到了这个时候，我们需要更好地定义互斥规则：只有在特定条件被满足时，互斥性才能够被保证。这个条件是，在步骤 3 中获得锁的客户端要某个时间前结束工作，这个时间就是锁的有效时间减去一小段时间（大概几毫秒，用于补充进程间的时钟漂移）。</p><p>你可以阅读 <a href="http://dl.acm.org/citation.cfm?id=74870" target=_blank rel="noopener noreferrer">《Leases：一个高效、可容错的分布式文件缓存一致性机制》</a>
，它是发表在 ACM 上的一篇论文，其中包含了更多关于绑定时钟漂移的介绍。</p><h3 id=失败重试>失败重试<a hidden class=anchor aria-hidden=true href=#失败重试>#</a></h3><p>当某个客户端不能获得锁时，它应该在随机延迟后重试，以便尝试取消多个试图同时获取同一资源锁的客户端的同步（这可能会导致无人获胜的脑裂情况）。此外，在大多数 Redis 实例中，客户端尝试获取锁的速度越快，脑裂情况的时间窗口就越小（并且需要重试）。因此，在理想情况下，客户端应该尝试使用多路复用技术，同时向 N 个实例发送 <code>SET</code> 命令。</p><p>值得强调的是，对于未能获得多数锁的客户来说，尽快释放（部分）获得的锁是十分重要的。这样一来，它就不需要等待 key 过期才能再次获取锁（但是，如果发生网络分区，客户端就不再能够与 Redis 实例通信，那么在等待 key 过期时，系统的可用性会降低）。</p><h3 id=锁释放>锁释放<a hidden class=anchor aria-hidden=true href=#锁释放>#</a></h3><p>释放锁是很简单的，无论客户端认为自己能够成功锁定给定的实例，它都可以执行释放锁。</p><h3 id=安全保证>安全保证<a hidden class=anchor aria-hidden=true href=#安全保证>#</a></h3><p>这个算法是安全的吗？我们可以设想以下场景来验证。</p><p>作为开始，让我们假设客户端能够获得多数实例的锁。所有的实例上都有一个相同的 key，并且它们的存活时间也相同。然而，这个 key 是在不同时间被设置的，因此它们的过期时间是不同的。但是，我们可以假设一种最坏的情况，即：第一个 key 设置于 T1 时刻（假设此时还未与第一个服务端通信），而最后一个 key 设置于 T2（假设此时获得到了最后一个服务端的响应），那么我们可以确定第一个 key 至少会存活 <code>MIN_VALIDITY = TTL - (T2 - T1) - CLOCK_DRIFT</code> 那么长的时间。所有其他的 key 都会在这之后过期，那么我们就可以确定这些 key 会被同时设置至少一次。</p><p>在这段时间里，多数 key 都被设置，另一个客户端将不能够获得锁，因为 <code>SET NX</code> 不可能成功 <code>N/2 + 1</code> 次，如果已经存在了 <code>N/2 + 1</code> 个 key 的话。因此，如果一个锁已被获得，它就不可能同时又被重新获得（破坏互斥性）。</p><p>不过，我们还需要确保多个客户端同时尝试获得锁时，它们不会同时成功。</p><p>如果客户端在一个接近于或是大于锁最大有效时间（就是使用 <code>SET</code> 命令时的 <code>TTL</code>）之内，锁住了多数实例，它就会认为这个锁是无效的，继而解锁所有实例。所以，我们只需要考虑一种情况：当客户端能够在锁有效时间内，成功锁住多数实例。在这个情况下，由于前面已经提到的原因，客户端将无法重新获得锁。因此，当多个客户端能够同时锁定 <code>N/2 + 1</code> 个实例（在步骤 2 中描述的时间内），当且仅当锁住多数实例的耗时要大于 <code>TTL</code>，而这样在这种情况下锁是无效的。</p><h3 id=存活保证>存活保证<a hidden class=anchor aria-hidden=true href=#存活保证>#</a></h3><p>系统存活性依赖于下面三个主要特性：</p><ol><li>锁自动释放（key 过期）：最终 key 是可以被重新上锁的。</li><li>当不能获得锁时，或者当获得了锁，工作结束后，客户端通常都会配合地删除锁。这使得我们很大概率不需要等待 key 过期才能重新获得锁。</li><li>当客户端需要重试锁时，它会延迟一段时间，这段时间和获得锁所需时间相比要长，这样一来可以从概率上，避免发生资源争用时的脑裂情况。</li></ol><p>然而，由于使用了多台主节点，当网络分区时，我们将会损失 <code>TTL</code> 这么长时间的可用性。如果网络分区持续存在的话，我们的系统将持续不可用。这种情况有可能会发生，如果客户端获得了锁，却在释放锁之前就被分区了的话。</p><h2 id=后语>后语<a hidden class=anchor aria-hidden=true href=#后语>#</a></h2><p>下一篇文章，我将介绍 Redis 的数据结构。保持关注喔！</p><h2 id=参考>参考<a hidden class=anchor aria-hidden=true href=#参考>#</a></h2><ul><li><a href=https://redis.io/docs/reference/patterns/distributed-locks/ target=_blank rel="noopener noreferrer">Redis Documentation - Distributed Locks with Redis</a></li></ul><hr><blockquote><p>本文使用 <a href=https://creativecommons.org/licenses/by-sa/4.0/deed.zh target=_blank rel="noopener noreferrer">CC BY-SA 4.0 国际协议</a>
进行许可，欢迎<strong>遵照协议规定</strong>转载。<br>作者：<a href=https://github.com/lkxed/ target=_blank rel="noopener noreferrer">六开箱</a><br>链接：<a href=https://lkxed.github.io/posts/redis-distributed-locks/ target=_blank rel="noopener noreferrer">https://lkxed.github.io/posts/redis-distributed-locks/</a></p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=https://lkxed.github.io/tags/redis/>Redis</a></li><li><a href=https://lkxed.github.io/tags/%E4%BD%BF%E7%94%A8/>使用</a></li><li><a href=https://lkxed.github.io/tags/%E6%95%99%E7%A8%8B/>教程</a></li></ul><nav class=paginav><a class=next href=https://lkxed.github.io/posts/redis-bulk-loading/><span class=title>下一页 »</span><br><span>Redis 用例：批量加载数据</span></a></nav></footer><script src=https://giscus.app/client.js data-repo=lkxed/lkxed.github.io data-repo-id=R_kgDOHF00eA data-category=Announcements data-category-id=DIC_kwDOHF00eM4COXzh data-mapping=og:title data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></article></main><footer class=footer><div class=social-icons><a href=https://github.com/lkxed/ target=_blank rel="noopener noreferrer me" title=GitHub><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a><a href=https://space.bilibili.com/88033726/ target=_blank rel="noopener noreferrer me" title=Bilibili><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" xmlns="http://www.w3.org/2000/svg"><rect x="1.3333" y="6" width="21.333" height="15.333" rx="4" ry="4"/><path d="m8 12.4v1.2"/><path d="m16 12.4v1.2"/><path d="m5.8853 2.6667L8.552 5.3334"/><path d="m18.115 2.6667-2.6667 2.6667"/></svg></a></div><span>&copy; 2022 <a href=https://lkxed.github.io/>六开箱</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/lkxed/hugo-PaperMod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerText="复制";function s(){e.innerText="已复制！",setTimeout(()=>{e.innerText="复制"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>